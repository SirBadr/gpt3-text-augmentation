{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6f0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e087977",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../semeval22_structured_sentiment/data/\" # update this with your data path\n",
    "mpqa_dir = data_dir + \"mpqa/\"\n",
    "darmstadt_dir = data_dir + \"darmstadt_unis/\"\n",
    "opener_dir = data_dir + \"opener_en/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662ed083",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpqa_train_json = mpqa_dir + \"train.json\"\n",
    "darmstadt_train_json = darmstadt_dir + \"train.json\"\n",
    "opener_train_json = opener_dir + \"train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9906c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code to merge all train.json files from above datasets to use them with GPT-J Prompt!\n",
    "files=[mpqa_train_json,darmstadt_train_json,opener_train_json]\n",
    "\n",
    "def merge_JsonFiles(filename):\n",
    "    result = list()\n",
    "    for f1 in filename:\n",
    "        with open(f1, 'r') as infile:\n",
    "            result.extend(json.load(infile))\n",
    "\n",
    "    with open('combinedTrain.json', 'w') as output_file:\n",
    "        json.dump(result, output_file)\n",
    "\n",
    "merge_JsonFiles(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e66b4c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5643\n",
      "2253\n",
      "1744\n",
      "9640\n"
     ]
    }
   ],
   "source": [
    "mpqaaa = 0\n",
    "with open(mpqa_train_json) as user_file:\n",
    "    mpqaaa = json.load(user_file)\n",
    "print(len(mpqaaa))\n",
    "\n",
    "darmaaa = 0\n",
    "with open(darmstadt_train_json) as user_file:\n",
    "    darmaaa = json.load(user_file)\n",
    "print(len(darmaaa))\n",
    "\n",
    "openerrr = 0\n",
    "with open(opener_train_json) as user_file:\n",
    "    openerrr = json.load(user_file)\n",
    "print(len(openerrr))\n",
    "\n",
    "combinedTrainContents = 0\n",
    "with open('combinedTrain.json') as user_file:\n",
    "    combinedTrainContents = json.load(user_file)\n",
    "print(len(combinedTrainContents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e9864d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3335\n"
     ]
    }
   ],
   "source": [
    "## code to remove texts with no sentiment!\n",
    "cleaned = list()\n",
    "combinedTrain = 0\n",
    "with open('combinedTrain.json') as data_file:    \n",
    "    combinedTrain = json.load(data_file)\n",
    "for v in data:\n",
    "    if(len(v[\"opinions\"]) != 0):\n",
    "        cleaned.append(v)\n",
    "        \n",
    "print(len(cleaned))\n",
    "with open('combinedTrainCleaned.json', 'w') as output_file:\n",
    "    json.dump(cleaned, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7423003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function returns two random text samples to use them as GPT-J prompt\n",
    "def get_two_random_samples(filename):\n",
    "    x = open(filename)\n",
    "    x = json.load(x)\n",
    "    s1, s2 = random.sample(range(0, len(x)), 2)\n",
    "    # return text1, label1, text2, label2\n",
    "    return x[s1]['text'], x[s1]['opinions'][0]['Polarity'], x[s2]['text'], x[s2]['opinions'][0]['Polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1572059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best in class', 'Positive', 'The IHRC said in a statement to mark December 10 , \" international day for human rights \" that the international community has formulated numerous documents to honor human rights after 50 years of bitter experience and the heavy losses that the humanity has suffered .', 'Positive')\n"
     ]
    }
   ],
   "source": [
    "print(get_two_random_samples('combinedTrainCleaned.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4481d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(text1, label1, text2, label2):\n",
    "    # define a function that takes as input two samples and generates the prompt\n",
    "    # that we should pass to the GPT-3 language model for completion.\n",
    "    description = \"Each item in the following list contains a tweet and the respective sentiment. Sentiment is one of 'Positive' or 'Negative'.\"\n",
    "    prompt = (f\"{description}\\n\"\n",
    "            f\"Tweet: {text1} (Sentiment: {label1})\\n\"\n",
    "            f\"Tweet: {text2} (Sentiment: {label2})\\n\"\n",
    "            f\"Tweet:\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef706d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each item in the following list contains a tweet and the respective sentiment. Sentiment is one of 'Positive' or 'Negative'.\n",
      "Tweet: However despite previous discussions \" I have n't had as much progress on individual cases as I have wished to , \" she added . (Sentiment: Positive)\n",
      "Tweet: Breakfast is no go , but there are enough good locations everywhere to have a good coffee and snack in the morning . (Sentiment: Negative)\n",
      "Tweet:\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d = get_two_random_samples('combinedTrainCleaned.json');\n",
    "print(get_prompt(a,b,c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226eda37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
